{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import actor/movie data\n",
    "with open('./data/celebs.pickle', 'rb') as handle:\n",
    "    actor_list = pickle.load(handle, encoding='UTF-8')\n",
    "with open('./data/movies.pickle', 'rb') as handle:\n",
    "    movie_list = pickle.load(handle, encoding='UTF-8')\n",
    "with open('./data/characters.pickle', 'rb') as handle:\n",
    "    character_dict = pickle.load(handle, encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(actor_list))\n",
    "random.sample(actor_list, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(movie_list))\n",
    "random.sample(movie_list, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(character_dict))\n",
    "character_dict['Bruce Wayne']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create master list of entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate vars, transform count vectorizer\n",
    "character_list = list(character_dict.keys())\n",
    "all_entities = actor_list + movie_list + character_list\n",
    "\n",
    "actors_len = len(actor_list)\n",
    "movies_len = len(movie_list)\n",
    "character_len = len(character_list)\n",
    "\n",
    "actors_len + movies_len + character_len #Order matters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer='char', ngram_range=(1, 3)) #All 1-3 character sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "vec_transformed = vectorizer.fit_transform(all_entities) #Keep track of transformed object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_transformed #Sparse matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(vectorizer.vocabulary_))\n",
    "random.sample(vectorizer.vocabulary_.items(), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine similarity function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"Morgin Freiman\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input_transformed = vectorizer.transform([user_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = user_input_transformed.toarray()\n",
    "print(len(dense[0]), \"items in Morgin Freiman vector\")\n",
    "[t for t in dense[0]][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#See all query tokens\n",
    "[i for i in vectorizer.inverse_transform(dense)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search for index of a token\n",
    "search_token = 'mor'\n",
    "for token, i in vectorizer.vocabulary_.items():\n",
    "    if token == search_token:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform cosine similarity calculation between user input and all entities\n",
    "sim_scores = pairwise_kernels(\n",
    "                 vec_transformed, # Big sparse matrix of all entities\n",
    "                 user_input_transformed, # User's query\n",
    "                 metric='cosine').flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_scores[:10] #What's this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splice into entity-specific sub-groups\n",
    "actor_scores = sim_scores[:actors_len]\n",
    "movie_scores = sim_scores[actors_len:actors_len+movies_len]\n",
    "character_scores = sim_scores[actors_len+movies_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(actor_list[:3])\n",
    "print(actor_scores[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Suspiciously JSON-like formatting\n",
    "actor_dict = [{\"type\":\"actor\", \"value\":a, \"similarity_score\":s} for a, s in zip(actor_list, actor_scores)]\n",
    "movie_dict = [{\"type\":\"movie\", \"value\":m, \"similarity_score\":s} for m, s in zip(movie_list, movie_scores)]\n",
    "\n",
    "#For each character score, put in actor's name\n",
    "actor_character_dict = []\n",
    "for character, score in zip(character_list,character_scores):\n",
    "    for actor in character_dict[character]:\n",
    "        actor_character_dict.append({\"type\":\"actor\", \"value\":actor, \"similarity_score\":score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dict = actor_dict + movie_dict + actor_character_dict\n",
    "    \n",
    "#Top 100 items sorted by similarity score\n",
    "all_dict_sorted = sorted(all_dict, key=itemgetter('similarity_score'), reverse=True)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dict_sorted[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All-in-one function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main function - given user input, return object of similar entities\n",
    "def getSimilarNames(user_input):\n",
    "\n",
    "    #Perform cosine similarity calculation between user input and all entities\n",
    "    sim_scores = pairwise_kernels(\n",
    "                     vec_transformed,\n",
    "                     vectorizer.transform([user_input]),\n",
    "                     metric='cosine').flatten().tolist()\n",
    "    \n",
    "    actor_scores = sim_scores[:actors_len]\n",
    "    movie_scores = sim_scores[actors_len:actors_len+movies_len]\n",
    "    character_scores = sim_scores[actors_len+movies_len:]\n",
    "    \n",
    "    actor_dict = [{\"type\":\"actor\", \"value\":a, \"similarity_score\":s} for a, s in zip(actor_list, actor_scores)]\n",
    "    movie_dict = [{\"type\":\"movie\", \"value\":m, \"similarity_score\":s} for m, s in zip(movie_list, movie_scores)]\n",
    "\n",
    "    actor_character_dict = []\n",
    "    for character, score in zip(character_list,character_scores):\n",
    "        for actor in character_dict[character]:\n",
    "            actor_character_dict.append({\"type\":\"actor\", \"value\":actor, \"similarity_score\":score})\n",
    "    \n",
    "    all_dict = actor_dict + movie_dict + actor_character_dict\n",
    "    \n",
    "    #Top 100 items sorted by similarity score\n",
    "    all_dict_sorted = sorted(all_dict, key=itemgetter('similarity_score'), reverse=True)[:100]\n",
    "    \n",
    "    return all_dict_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#Provide search to fuzzy lookup\n",
    "getSimilarNames('thor')[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
